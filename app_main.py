# app_main.py (ìµœì¢… ìë™í™” ë²„ì „)

# -*- coding: utf-8 -*-

# app_main.py
# ì´ íŒŒì¼ì€ Streamlit UIì™€ ë©”ì¸ ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

import os, json, time, re as regx
import streamlit as st
import pandas as pd
import numpy as np
import datetime
from typing import List, Dict, Tuple

# analytics_core ëª¨ë“ˆì—ì„œ ëª¨ë“  í•„ìš”í•œ í•¨ìˆ˜ì™€ ìƒìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from analytics_core import (
    read_csv_robust, categorize_term, _parse_json_safely,
    coerce_article_id, build_topic_term_bank_logreg, # LogReg í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
    infer_topic_for_text, get_topic_keywords_from_bank,
    llm_rerank_or_generate, build_engagement, label_quality_by_quantile,
    get_topic_top_words, llm_name_topics, compute_sentiment_SI,
    get_sentiment_for_text, get_recent_popular_words,
    get_suspected_stopwords, fit_ols, tidy_summary,
    create_sentiment_gauge_S, create_sentiment_gauge_I,
    prepare_by_mode,
    # ìƒˆë¡œìš´ í•™ìŠµ ë° ë¹„êµ í•¨ìˆ˜ import
    train_quality_classifier, evaluate_comparison_models,
    evaluate_baseline_models, 
    # [ì¶”ê°€] íŒŒì¸íŠœë‹ ìë™í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜ import
    run_finetuning_job,
    build_topic_term_bank_rf_logratio, # â˜…â˜…â˜… RandomForest ê¸°ë°˜ í•¨ìˆ˜ import (TAB2ì—ì„œ ì‚¬ìš©) â˜…â˜…â˜…
    # =================================
    MODE_CFG, DEFAULT_CANDIDATES, LLM_OK, client,
    cached_lda_run_wrapper, STOPWORDS_KO, MODEL_CHAT, APIError, RateLimitError,
    train_test_split, TfidfVectorizer, SGDClassifier, confusion_matrix, classification_report,
    RobustScaler,   # Scaler ê°ì²´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ import
    BASELINE_FEATURES # BASELINE_FEATURES ë¦¬ìŠ¤íŠ¸ import
)
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI

# ================== CONFIG (ë©”ì¸ ì•±ì—ì„œë§Œ ì‚¬ìš©í•˜ëŠ”) ==================
# [ì‹ ê·œ] íŒŒì¸íŠœë‹ ì„¤ì • (ì™„ë£Œ ê°€ì •)
USE_FINETUNED_MODEL = True
FINETUNED_MODEL_ID_DEFAULT = "ft:gpt-4o-mini-2024-07-18:::CWPoHwfK" 

def require_llm():
    if not LLM_OK:
        st.error("APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: OPENAI_API_KEY/ë„¤íŠ¸ì›Œí¬/ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

# ========= Streamlit UI / Main Logic =========
def main():
    st.set_page_config(page_title="ë¬¸ë§¥í˜• ì¶”ì²œ + ì„±ê³¼ ë¶„ì„ + ê°ì„±/íšŒê·€", page_icon="ğŸ“", layout="wide")
    st.title("Team 5_í†µê³„ì ë°ì´í„°ê³¼í•™")

    with st.sidebar:
        st.subheader("ê³µí†µ ì„¤ì •")
        audience = st.selectbox("ì£¼ìš” ë…ì ìˆ˜ì¤€", ["ì…ë¬¸ì", "ì „ë¬¸ê°€", "í˜¼í•©"], index=2)
        tone = st.selectbox("ì½˜í…ì¸  í†¤/ìŠ¤íƒ€ì¼", ["ì¹œê·¼", "ê³µì‹", "ë¶„ì„ì "], index=2)
        if LLM_OK: st.success("LLM ìƒíƒœ: âœ… ì—°ê²° OK")
        elif client: st.error("LLM ìƒíƒœ: âŒ ì¸ì¦/ê¶Œí•œ/ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜")
        else: st.error("LLM ìƒíƒœ: âŒ OPENAI_API_KEY ë¯¸ì„¤ì •")

    # [ìˆ˜ì •] TAB4_FT (íŒŒì¸íŠœë‹ ê´€ë¦¬ì) ì¶”ê°€
    TAB1, TAB2, TAB3_ADMIN, TAB4_FT = st.tabs([
        "ğŸ’¡ ë¬¸ë§¥í˜• ìš©ì–´ ì¶”ì²œ",
        "ğŸ“ˆ ì„±ê³¼/ì£¼ì œ/ê°ì„± ë¶„ì„",
        "ğŸ”¬ ëª¨ë¸ ê´€ë¦¬ì (Admin)",
        "ğŸ¤– íŒŒì¸íŠœë‹ ê´€ë¦¬ì (FT)"
    ])

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    for _k, _v in [
        ("last_recs", None),
        ("last_recs_time", None),
        ("last_draft", ""),
        ("last_candidates", []),
        ("sentiment_pack", None),
        ("df_for_analysis", None),
        ("analysis_done", False),
        ("ft_model_id", FINETUNED_MODEL_ID_DEFAULT), 
        ("lda_vect", None),
        ("lda_model", None),
        ("clf_pack_base", None), 
        ("clf_pack_adv", None),   
        ("topic_term_bank", None),
        ("ft_job_id", None),
        ("comparison_results", None), # TAB3 ë¹„êµ ê²°ê³¼ ì €ì¥
        ("ft_training_file", None), # [ì‹ ê·œ] íŒŒì¸íŠœë‹ í•™ìŠµ íŒŒì¼
    ]:
        st.session_state.setdefault(_k, _v)

    # íŒŒì¸íŠœë‹ ëª¨ë“œ í™•ì¸ (ë©”ì¸ UI ë¡œì§ì—ì„œë§Œ ì‚¬ìš©)
    DUMMY_ID = "ft:gpt-4o-mini-DUMMY_ID_INIT"
    FINETUNED_MODEL_ID_CURRENT = st.session_state.get('ft_model_id', DUMMY_ID)
    is_ft_model_ready = USE_FINETUNED_MODEL and FINETUNED_MODEL_ID_CURRENT.startswith("ft:") and FINETUNED_MODEL_ID_CURRENT != DUMMY_ID


    # ================= TAB1 =================
    with TAB1:
        st.header("1) ì´ˆì•ˆ í…ìŠ¤íŠ¸ ì…ë ¥ ë° ë¶„ì„ ëª¨ë“œ ì„ íƒ")
        
        # [ìˆ˜ì • 1] Baseline / Advanced ëª¨ë“œ ì„ íƒ
        mode = st.radio(
            "ë¶„ì„/ì¶”ì²œ ëª¨ë“œ ì„ íƒ",
            ["Advanced Mode (í† í”½ + í”¼ì²˜)", "Baseline Mode (ìˆ˜ì¹˜ í”¼ì²˜ë§Œ)"],
            index=0,
            horizontal=True,
            help="Advanced: í…ìŠ¤íŠ¸ ì˜ë¯¸(í† í”½)ì™€ ìˆ˜ì¹˜ì  íŠ¹ì§• ëª¨ë‘ ì‚¬ìš©. Baseline: img_count, length ë“± ìˆ˜ì¹˜ì  íŠ¹ì§•ë§Œ ì‚¬ìš©."
        )
        selected_clf_pack = st.session_state.get("clf_pack_adv" if mode.startswith("Advanced") else "clf_pack_base")

        # --- ì œëª© ì…ë ¥ ë° ê¸¸ì´ í‘œì‹œ ---
        draft_title = st.text_input("ì œëª© (ì„ íƒ)", placeholder="ì˜ˆ: ì´ë²ˆ ì£¼ AI íŠ¸ë Œë“œ Top 5")
        current_title_len = len(draft_title.strip())
        st.caption(f"**ì œëª© ê¸¸ì´:** {current_title_len}ì")
        
        # --- ë³¸ë¬¸ ì…ë ¥ ë° ê¸¸ì´ í‘œì‹œ ---
        draft_body = st.text_area("ë³¸ë¬¸ (ì´ˆì•ˆ)", height=220,
                                     placeholder="ì˜ˆ) 1. ì˜¤í”ˆAIì˜ ìƒˆ ëª¨ë¸ì´...")
        current_content_len = len(draft_body.strip())
        st.caption(f"**ë³¸ë¬¸ ê¸¸ì´:** {current_content_len}ì")
        
        # [ìˆ˜ì • 2] ìˆ˜ì¹˜ í”¼ì²˜ ì…ë ¥ ë°›ê¸° (ê¸¸ì´ëŠ” ì´ë¯¸ ê³„ì‚°ë¨)
        st.markdown("---")
        st.subheader("1-1) ì´ë¯¸ì§€ ìˆ˜ ì…ë ¥ (ì„±ê³¼ í™•ë¥  ì˜ˆì¸¡ì— ì‚¬ìš©)")
        
        # ê¸°ë³¸ê°’ ì„¤ì • (í‰ê· ê°’)
        df_analysis = st.session_state.get('df_for_analysis')
        if df_analysis is not None and not df_analysis.empty:
            img_default = int(df_analysis['img_count'].mean())
        else:
            img_default = 3

        # ì´ë¯¸ì§€ ìˆ˜ë§Œ ì…ë ¥ë°›ëŠ” UI
        img_count = st.number_input("ì´ë¯¸ì§€ ìˆ˜ (img_count)", min_value=0, value=img_default, key='ui_img_count')
        st.markdown("---")


        full_draft = draft_title.strip() + " " + draft_body.strip()

        c_date, c_check = st.columns([1, 1])
        with c_date:
            ref_date = st.date_input("ê¸°ì¤€ ë‚ ì§œ", datetime.date.today())
        with c_check:
            st.write("")
            st.write("")
            all_dates = st.checkbox("ëª¨ë“  ë‚ ì§œ ì„ íƒí•˜ê¸° (ì „ì²´ ê¸°ê°„ ë¶„ì„)", value=True)

        candidates = list(DEFAULT_CANDIDATES)
        topic_id_for_draft, topic_dist = None, None
        topic_name = "ë¯¸ë¶„ë¥˜"

        # ì„¸ì…˜ì—ì„œ í•„ìš”í•œ ëª¨ë¸/ë°ì´í„° ë¡œë“œ
        topic_bank = st.session_state.get("topic_term_bank")
        lda_vect    = st.session_state.get("lda_vect")
        lda_model   = st.session_state.get("lda_model")
        senti_pack = st.session_state.get('sentiment_pack')
        df_all_data = st.session_state.get('df_for_analysis')

        # [ì‹ ê·œ] ë°ì´í„° ë¯¸ë¡œë“œ ì‹œ ê²½ê³ 
        if not st.session_state['analysis_done']:
            st.warning("âš ï¸ **ë°ì´í„° ë¯¸ë¡œë“œ:** TAB2ì—ì„œ CSV ì—…ë¡œë“œ ë° ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê³¼ê±° ë°ì´í„° ê¸°ë°˜ì˜ í™•ë¥ , ì£¼ì œ, í‚¤ì›Œë“œ ì¶”ì²œì´ í™œì„±í™”ë©ë‹ˆë‹¤.")


        # --- 1. í† í”½ ì¶”ë¡  ë° íƒœê·¸ í‘œì‹œ (Advanced Modeì—ì„œë§Œ) ---
        if full_draft.strip() and mode.startswith("Advanced") and topic_bank and lda_vect is not None and lda_model is not None:
            topic_id_for_draft, topic_dist = infer_topic_for_text(full_draft, lda_vect, lda_model)

            topic_name = f"í† í”½ {topic_id_for_draft}"
            topic_desc = "ë¶„ì„ëœ ì£¼ì œ"
            lbls = st.session_state.get("topic_labels", {})
            if f"Topic {topic_id_for_draft}" in lbls:
                meta = lbls[f"Topic {topic_id_for_draft}"]
                topic_name = meta.get('name', topic_name)
                topic_desc = meta.get('desc', topic_desc)
                
            # í•´ë‹¹ í† í”½ì˜ ì„±ê³¼ ìš°ìˆ˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ í›„ë³´ ë‹¨ì–´ë¡œ ì‚¬ìš©
            topic_keywords_data = get_topic_keywords_from_bank(topic_bank, int(topic_id_for_draft), k_each=30)
            candidates = list(dict.fromkeys([w for w, s in topic_keywords_data.get("good", [])] + DEFAULT_CANDIDATES))


            st.markdown(f"**ì´ˆì•ˆì˜ ì˜ˆìƒ ì£¼ì œ:** <span style='background-color: #0072F0; color: white; padding: 3px 8px; border-radius: 15px; font-size: 0.9em; margin-left: 10px;'>{topic_name}</span>", unsafe_allow_html=True)
            
            # [ìˆ˜ì • ë°˜ì˜] í›„ë³´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ Expanderë¡œ ê°ì‹¸ì„œ í‘œì‹œ
            with st.expander(f"í›„ë³´ ë‹¨ì–´ ({len(candidates)}ê°œ) í¼ì³ë³´ê¸°"):
                st.caption(f"â”” {topic_desc} (í† í”½: {topic_id_for_draft}) ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œëœ **ì„±ê³¼ ìš°ìˆ˜ ë‹¨ì–´** ë° ê¸°ë³¸ ë‹¨ì–´ í’€ì…ë‹ˆë‹¤.")
                st.code(", ".join(candidates)) # í›„ë³´ ë‹¨ì–´ ëª©ë¡ì„ code ë¸”ë¡ìœ¼ë¡œ í‘œì‹œ


        elif mode.startswith("Advanced"):
            st.caption("â„¹ï¸ Advanced ModeëŠ” TAB2ì—ì„œ LDA ë¶„ì„ì´ ì™„ë£Œëœ í›„ í™œì„±í™”ë©ë‹ˆë‹¤.")


        # --- 2. ë“±ê¸‰/í™•ë¥  ë° í‚¤ì›Œë“œ ì¶”ì²œ (ë¶„ë¥˜ê¸° ë¡œë“œ ì‹œ) ---
        if full_draft.strip() and selected_clf_pack is not None:
            clf = selected_clf_pack["clf"]
            
            # [í•µì‹¬ ìˆ˜ì • 3] ì˜ˆì¸¡ í”¼ì²˜ êµ¬ì„± (scaler ì‚¬ìš©)
            try:
                # 1. ìˆ˜ì¹˜ í”¼ì²˜ (ì‚¬ìš©ì ì…ë ¥/ìë™ ê³„ì‚°ëœ ê¸¸ì´)
                X_num_raw = np.array([[img_count, current_title_len, current_content_len]])
                
                # 2. Scalerë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì¹˜ í”¼ì²˜ ë³€í™˜
                scaler = selected_clf_pack.get("scaler")
                if scaler is None:
                    raise ValueError("í•™ìŠµëœ Scaler ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤. TAB2ì—ì„œ ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    
                X_num_scaled = scaler.transform(X_num_raw)
                
                if mode.startswith("Advanced"):
                    # Advanced: Tfidf + Scaled Numerical + Topic One-Hot
                    tfidf = selected_clf_pack["tfidf"]
                    
                    # 3. í…ìŠ¤íŠ¸ Tfidf í”¼ì²˜
                    X_text = tfidf.transform([full_draft]).toarray()
                    
                    # 4. í† í”½ í”¼ì²˜ (One-Hot)
                    topic_cols = [f for f in selected_clf_pack["features"] if f.startswith('topic_')]
                    X_topic = np.zeros((1, len(topic_cols)))
                    
                    if topic_id_for_draft is not None:
                        topic_one_hot_key = f'topic_{topic_id_for_draft}'
                        if topic_one_hot_key in selected_clf_pack["features"]:
                            # Xd êµ¬ì„±ì— ë§ê²Œ í† í”½ ì›í•« ì¸ë±ìŠ¤ ê³„ì‚° (Tfidf + Scaled Num ì´í›„)
                            tfidf_feature_count = len(tfidf.get_feature_names_out())
                            num_feature_count = len(BASELINE_FEATURES)
                            topic_one_hot_index = selected_clf_pack["features"].index(topic_one_hot_key) - (tfidf_feature_count + num_feature_count)
                            
                            if 0 <= topic_one_hot_index < len(topic_cols):
                                X_topic[0, topic_one_hot_index] = 1
                    
                    # ìµœì¢… í”¼ì²˜ ë²¡í„°: Tfidf + Scaled Numerical + Topic One-Hot
                    Xd = np.hstack([X_text, X_num_scaled, X_topic])

                else: # Baseline Mode
                    # Baseline: Scaled Numerical Featureë§Œ ì‚¬ìš©
                    Xd = X_num_scaled

                # ì˜ˆì¸¡
                if Xd.shape[1] == len(selected_clf_pack['features']):
                    proba_good = float(clf.predict_proba(Xd)[0,1])
                    label = "ìƒ (Good)" if proba_good >= 0.5 else "í•˜ (Bad)"
                else:
                    proba_good = 0.5
                    label = f"ì˜¤ë¥˜: í”¼ì²˜ ìˆ˜ ë¶ˆì¼ì¹˜ ({Xd.shape[1]} vs {len(selected_clf_pack['features'])})"
                    st.warning(f"ì˜ˆì¸¡ í”¼ì²˜ ê°œìˆ˜ê°€ ëª¨ë¸({selected_clf_pack['mode']}) í•™ìŠµ í”¼ì²˜ ê°œìˆ˜ì™€ ë‹¤ë¦…ë‹ˆë‹¤. (ì˜ˆì¸¡: {Xd.shape[1]}, í•™ìŠµ: {len(selected_clf_pack['features'])})")

            except Exception as e:
                proba_good = 0.5
                label = f"ì˜ˆì¸¡ ì˜¤ë¥˜"
                st.error(f"ì˜ˆì¸¡ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")


            c1, c2 = st.columns(2)
            c1.metric(f"ì˜ˆìƒ ì½˜í…ì¸  ë§¤ë ¥ ë“±ê¸‰ ({mode})", label)
            c2.metric("ğŸ“ˆ ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ì„±ê³¼ í™•ë¥ ", f"{proba_good*100:.1f}%")

            st.caption(f"â”” ê³¼ê±° ë°ì´í„°(TAB2)ë¡œ í•™ìŠµí•œ **{mode} ëª¨ë¸**ì˜ ì˜ˆì¸¡ì¹˜ì…ë‹ˆë‹¤. (ëª¨ë¸ íƒ€ì…: {selected_clf_pack.get('model_type', 'ë¶ˆëª…')})")
            
            # --- í‚¤ì›Œë“œ ì¶”ì²œ ì„¹ì…˜ (Advanced Modeì—ë§Œ í•´ë‹¹) ---
            if not is_ft_model_ready and mode.startswith("Advanced"):
                if all_dates:
                    if topic_id_for_draft is not None and topic_bank:
                        topic_keywords_data = get_topic_keywords_from_bank(topic_bank, int(topic_id_for_draft), k_each=10)
                        good_topic_terms = [w for w,s in topic_keywords_data.get("good", [])]
                        if good_topic_terms:
                            with st.expander(f"âœ… **'{topic_name}' ì£¼ì œ**ì˜ **ì „ì²´ ê¸°ê°„** ì„±ê³¼ ìš°ìˆ˜ ë‹¨ì–´ (ì¶”ì²œ)"):
                                st.markdown(f"**ì´ìœ :** ê³¼ê±° ì´ ì£¼ì œ(`{topic_name}`)ì˜ ì½˜í…ì¸  ì¤‘ **ë†’ì€ ì„±ê³¼**ë¥¼ ë‚¸ ë¬¸ì„œì—ì„œ ìì£¼ ë°œê²¬ëœ ë‹¨ì–´ë“¤ì…ë‹ˆë‹¤.")
                                st.info(", ".join(good_topic_terms))
                            # candidates ë¦¬ìŠ¤íŠ¸ê°€ ì´ë¯¸ ìœ„ì—ì„œ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” pass
            
            st.divider()

            # --- 3. ê°ì„± ì ìˆ˜ (ê°ì„± ì‚¬ì „ ë¡œë“œ ì‹œ) ---
            if senti_pack and senti_pack.get('cv') and senti_pack.get('lex'):
                senti_s, senti_i = get_sentiment_for_text(full_draft, senti_pack)
                target_s = senti_pack.get('target_s')
                target_i = senti_pack.get('target_i')

                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(create_sentiment_gauge_S(senti_s, target_s), use_container_width=True)
                with col2:
                    st.plotly_chart(create_sentiment_gauge_I(senti_i, target_i), use_container_width=True)

                if target_s is not None and target_i is not None:
                    st.markdown(f"**ğŸ¯ ëª©í‘œ ì ìˆ˜** (Good ì½˜í…ì¸  í‰ê· ): **S (ì ìˆ˜): {target_s:.2f}** | **I (ê°•ë„): {target_i:.2f}**")
            
            st.divider()

        # --- 4. LLM ì¶”ì²œ/ìƒì„± (ë©”ì¸ ë¡œì§ ìŠ¤ìœ„ì¹˜) ---
        if is_ft_model_ready:
            st.subheader("2) ğŸ¤– AI ì œëª© ìƒì„±ê¸° (íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© ì¤‘)")
            st.caption(f"íŒŒì¸íŠœë‹ëœ ëª¨ë¸({FINETUNED_MODEL_ID_CURRENT[:20]}...)ì´ ë¶„ì„ ëŒ€ì‹  **ì œëª©ì„ ì§ì ‘ ìƒì„±**í•©ë‹ˆë‹¤. (ìµœëŒ€ 20ê°œ ë‚´ì™¸)")
            
            # [ìˆ˜ì • ë°˜ì˜] íŒŒì¸íŠœë‹ ëª¨ë“œì—ì„œ topk ìŠ¬ë¼ì´ë” ì œê±° ë° ê³ ì • ê°’ ì„¤ì •
            topk = 20
            
            btn_label = "âœ¨ AI ì œëª© ìƒì„± ì‹œì‘"
        else:
            st.subheader("2) LLM ë¦¬ë­ì»¤ (í†µê³„ ê¸°ë°˜ í›„ë³´ ì‚¬ìš© ì¤‘)")
            topk = st.slider("ì¶”ì²œ ê°œìˆ˜ (Top-K)", 3, 15, 8)
            btn_label = "âœ¨ ë¬¸ë§¥í˜• ìš©ì–´ ì¶”ì²œ ìƒì„±"

        btn = st.button(btn_label, disabled=not LLM_OK)

        if btn:
            require_llm()
            if not full_draft.strip():
                st.warning("ì œëª©ì´ë‚˜ ë³¸ë¬¸ ì´ˆì•ˆ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            elif mode.startswith("Baseline"):
                st.warning("Baseline Modeì—ì„œëŠ” í‚¤ì›Œë“œ ì¶”ì²œ ë¡œì§ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Advanced Modeë¡œ ì „í™˜í•˜ê±°ë‚˜, íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            else:
                with st.spinner("LLMì´ ì œëª©ì„ ìƒì„±/ì„ ë³„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        recs = llm_rerank_or_generate(
                            draft_title=draft_title,
                            draft_body=draft_body,
                            candidates=candidates,
                            topic_name=topic_name,
                            topk=topk,
                            audience=audience,
                            tone=tone,
                            temperature=0.2,
                            use_finetuned=is_ft_model_ready,
                            ft_model_id=FINETUNED_MODEL_ID_CURRENT
                        )
                        st.session_state["last_recs"] = recs
                        st.session_state["last_recs_time"] = time.strftime("%Y-%m-%d %H:%M:%S")

                        st.success("ì¶”ì²œ ì™„ë£Œ!")
                        st.session_state["last_draft"] = full_draft
                        st.session_state["last_candidates"] = list(candidates)
                    except (APIError, RateLimitError) as e:
                        st.error(f"OpenAI API ì˜¤ë¥˜ (í• ë‹¹ëŸ‰, ì¸ì¦ ë“±): {e}")
                    except Exception as e:
                        st.error(str(e))


        if st.session_state.get("last_recs"):
            if is_ft_model_ready:
                st.subheader("âœ… AI ìƒì„± ì œëª© í›„ë³´ (Top-K)")
                result_label = "AI ìƒì„± ì œëª© í›„ë³´"
            else:
                st.subheader("âœ… LLM ë¦¬ë­ì»¤ ì¶”ì²œ ë‹¨ì–´")
                result_label = "ë¬¸ë§¥ ì¶”ì²œ ë‹¨ì–´ í›„ë³´"

            st.markdown(f"**ì´ {len(st.session_state['last_recs'])}ê°œì˜ {result_label}ê°€ ìˆìŠµë‹ˆë‹¤.**")
            st.markdown("---")

            # [ìˆ˜ì •ëœ ë¶€ë¶„: Expanderë¥¼ ìœ ì§€í•˜ê³  ë‚´ìš©ì„ ë³€ê²½]
            for i, r in enumerate(st.session_state["last_recs"], 1):
                term_text = r.get('term', '(ìš©ì–´)').strip()
                category_text = r.get('category', '')
                why_text = r.get('why', 'ì„¤ëª… ì—†ìŒ')
                example_text = r.get('insertion_example', 'ì˜ˆì‹œ ì—†ìŒ')
                expected_effect = r.get('expected_effect', 'ì •ë³´ ì—†ìŒ')

                st.markdown(f"**{i}. {term_text}** (ì¶”ì²œ ìœ„ì¹˜: {r.get('where_to_add', 'ìœ„ì¹˜ ë¶ˆëª…')})")
                
                # 'ìì„¸íˆ ë³´ê¸°' Expander ìœ ì§€
                with st.expander(f"ìì„¸íˆ ë³´ê¸°: {term_text}"):
                    
                    # íŒŒì¸íŠœë‹ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ ë¶„ë¥˜ í‘œì‹œ
                    if not is_ft_model_ready:
                        st.markdown(f"**ë¶„ë¥˜:** `{category_text}`")
                    
                    # [í•µì‹¬] ì¶”ì²œ ë§¥ë½/ì´ìœ  ê°•ì¡° (Why)
                    st.markdown(f"**ğŸ’¡ ì¶”ì²œ ë§¥ë½/ì´ìœ  (Why):**")
                    st.info(f"**{why_text}**") 
                    
                    # ì ìš© ì˜ˆì‹œ í•„ë“œëŠ” analytics_coreì—ì„œ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶œë ¥ ë¡œì§ì„ ê±´ë„ˆëœë‹ˆë‹¤.
                    
                    # ì˜ˆìƒ íš¨ê³¼ ê°•ì¡°
                    st.markdown(f"**ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼:** **{expected_effect}**")
                
                st.markdown("---")

            st.caption(f"â€¢ ìµœì¢… ì¶”ì²œì€ {st.session_state.get('last_recs_time', 'N/A')}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        else:
            st.info("ì•„ì§ ìƒì„±ëœ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")

        st.markdown("---")
        st.caption("â€¢ ì¶”ì²œ ìš©ì–´ëŠ” TAB2ì—ì„œ ë¶„ì„í•œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ 'í† í”½ë³„ í•µì‹¬ ë‹¨ì–´' í’€ì—ì„œ ì„ ë³„ë©ë‹ˆë‹¤.")

    # ================= TAB2 =================
    with TAB2:
        st.header("ğŸ“Š ë°ì´í„° ì—…ë¡œë“œ ë° ì„±ê³¼ ë¶„ì„")
        
        # [ìˆ˜ì •] ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë”ë¡œ ë³€ê²½
        f_data = st.file_uploader(
            "ğŸ“ (1) ì½˜í…ì¸  ë° ì„±ê³¼ ë°ì´í„° CSV (article_id, title, content, date, views_total, likes, comments, img_count, title_length, content_length í¬í•¨)", 
            type=["csv"], 
            key="data"
        )
        
        st.markdown("---")
        st.subheader("âš™ï¸ ë¶„ì„ ì„¤ì •")
        c3, c4, c5 = st.columns(3)
        lda_topics = c3.number_input("ì£¼ì œ ë¶„ë¥˜ ê°œìˆ˜ (LDA í† í”½ ìˆ˜)", min_value=5, max_value=40, value=10, step=1)
        c4.markdown("**ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜ ê°€ì¤‘ì¹˜** (ì´í•© 1.0)")
        wv = c4.slider("ì¡°íšŒìˆ˜ ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.4, 0.05, key="wv_slider")
        wl = c4.slider("ì¢‹ì•„ìš” ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.4, 0.05, key="wl_slider")
        wc = c4.slider("ëŒ“ê¸€ ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.2, 0.05, key="wc_slider")

        f_lex = c5.file_uploader("ğŸ’– ê°ì„± ì‚¬ì „ CSV (ì„ íƒ: word,score)", type=["csv"], key="lex")

        # íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ë°ì´í„° ë¡œë“œ (ë¶„ì„ ë²„íŠ¼ ë°–ì— ìœ„ì¹˜)
        if f_data is not None:
            try:
                is_new_file = False
                if st.session_state.get('f_data_name') != f_data.name:
                    st.session_state['analysis_done'] = False
                    st.session_state['f_data_name'] = f_data.name
                    is_new_file = True
                
                # [ìˆ˜ì •] ë‹¨ì¼ íŒŒì¼ ë¡œë“œ ë¡œì§
                if not st.session_state['analysis_done'] or is_new_file:
                    with st.spinner("ìƒˆë¡œìš´ íŒŒì¼ ê°ì§€. ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤..."):
                        df_raw = coerce_article_id(read_csv_robust(f_data))
                        
                        required_cols = ["title", "content", "views_total", "likes", "comments", "img_count"]
                        missing = [c for c in required_cols if c not in df_raw.columns]
                        if missing:
                            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)} ì´(ê°€) CSV íŒŒì¼ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
                            st.stop()

                        df_raw["article_id"] = df_raw["article_id"].astype(str)
                        for col in ["views_total", "likes", "comments", "img_count"]:
                            df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce').fillna(0)

                        if 'date' in df_raw.columns:
                            df_raw['date'] = pd.to_datetime(df_raw['date'], errors='coerce')
                        
                        df = build_engagement(df_raw, w_views=wv, w_likes=wl, w_comments=wc)
                        df = label_quality_by_quantile(df, col="engagement", low_q=0.33, high_q=0.66)

                        st.session_state['df_for_analysis'] = df.copy()
                        st.session_state['df_m_raw_for_viz'] = df_raw.copy()
                        st.success(f"ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)} ê±´. (ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”)")
                
                # ë“±ê¸‰ í™•ì¸ í‘œì‹œ
                df_full_display = st.session_state.get('df_for_analysis')
                if df_full_display is not None and not df_full_display.empty:
                    st.subheader("1. ì½˜í…ì¸  ë“±ê¸‰ í™•ì¸")
                    st.caption("ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜(Total Engagement)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 33%ëŠ” 'ìƒ (good)', í•˜ìœ„ 33%ëŠ” 'í•˜ (bad)'ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.")
                    grade_counts = df_full_display["quality_label"].value_counts().rename({"good": "ìƒ (Good)", "medium": "ì¤‘ (Medium)", "bad": "í•˜ (Bad)"})
                    st.dataframe(grade_counts.to_frame(name="ì½˜í…ì¸  ìˆ˜"), use_container_width=True)
                else:
                    st.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë°ì´í„° ë“±ê¸‰ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


                colm1, colm2 = st.columns(2)
                do_quick = colm1.button("âš¡ï¸ ë¹ ë¥¸ ë¶„ì„ (ìƒ˜í”Œ/ê²½ëŸ‰ ëª¨ë¸)", use_container_width=True)
                do_full = colm2.button("ğŸ”¬ ì •ë°€ ë¶„ì„ (ì „ì²´/ê³ ì •ë°€ ëª¨ë¸)", use_container_width=True)

                if do_quick or do_full:
                    # ----------------- ë¶„ì„ ì‹¤í–‰ ë¸”ë¡ ì‹œì‘ -----------------
                    mode = "quick" if do_quick else "full"
                    cfg = MODE_CFG[mode]

                    df_full_for_prep = st.session_state.get('df_for_analysis')
                    if df_full_for_prep is None or df_full_for_prep.empty:
                        st.error("ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: df_for_analysisê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                        st.stop()

                    df_work, lda_kw, clf_kw = prepare_by_mode(df_full_for_prep, cfg, lda_topics)
                    
                    # ===== LDA (Advanced Modeìš©) =====
                    st.subheader("2. ì£¼ì œ(í† í”½) ë¶„ë¥˜ ë° ë¶„ì„ (Advanced Modeìš©)")
                    with st.spinner(f"LDA({mode}) ì£¼ì œ ë¶„ì„ ì‹¤í–‰ ì¤‘â€¦"):
                        df_sig = tuple(df_work["content"].fillna("").tolist())
                        df_topic, vect, lda, W = cached_lda_run_wrapper(df_sig, **lda_kw)
                    
                    df_work["topic"] = df_topic["topic"]
                    st.write("ì£¼ì œ ë¶„ë¥˜ ê²°ê³¼ (ìƒ˜í”Œ):", df_work[["article_id","topic","title"]].head(10))

                    topics_top_words = get_topic_top_words(lda, vect, topn=8)
                    with st.spinner("LLM/íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í† í”½ ë¼ë²¨ë§ ì¤‘..."):
                        topic_labels = llm_name_topics(topics_top_words)

                    st.session_state["topic_labels"] = topic_labels
                    st.session_state["lda_vect"] = vect
                    st.session_state["lda_model"] = lda

                    # ì „ì²´ ë°ì´í„°ì— í† í”½ ë¶„ë¥˜ ì ìš© (TAB1/TAB3ì—ì„œ ì‚¬ìš©)
                    if 'df_for_analysis' in st.session_state and st.session_state['df_for_analysis'] is not None:
                        # [ìˆ˜ì •] ì œëª© ì œì™¸, ë³¸ë¬¸ë§Œ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                        full_texts = (st.session_state['df_for_analysis']["content"].fillna("")).tolist()
                    #full_texts = (st.session_state['df_for_analysis']["title"].fillna("") + " " + st.session_state['df_for_analysis']["content"].fillna("")).tolist()
                    full_X = vect.transform(full_texts)
                    full_topics = lda.transform(full_X).argmax(axis=1)
                    st.session_state['df_for_analysis']['topic'] = full_topics
                    st.info("ì „ì²´ ë°ì´í„°ì— í† í”½ ë¶„ë¥˜ ì ìš© ì™„ë£Œ.")

                    # ===== ë¶„ë¥˜ê¸° í•™ìŠµ (Baseline / Advanced) =====
                    st.subheader("3. ì½˜í…ì¸  ë“±ê¸‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
                    df_trainable = st.session_state['df_for_analysis'] 
                    
                    # 3-1. Baseline ëª¨ë¸ í•™ìŠµ (SGD ì‚¬ìš©)
                    with st.spinner(f"3-1. Baseline ëª¨ë¸ (ìˆ˜ì¹˜ í”¼ì²˜, SGD) í•™ìŠµ ì¤‘..."):
                        clf_pack_base = train_quality_classifier(df_trainable, "baseline", clf_kw, model_type="SGDClassifier")
                        st.session_state["clf_pack_base"] = clf_pack_base
                        st.success("Baseline ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                        
                    # 3-2. Advanced ëª¨ë¸ í•™ìŠµ (RandomForest ì‚¬ìš©)
                    with st.spinner(f"3-2. Advanced ëª¨ë¸ (í† í”½+í”¼ì²˜, RandomForest) í•™ìŠµ ì¤‘..."):
                        # â˜…â˜…â˜… Advanced ModeëŠ” RandomForest ì‚¬ìš© â˜…â˜…â˜…
                        clf_pack_adv = train_quality_classifier(df_trainable, "advanced", clf_kw, vect, model_type="RandomForest")
                        st.session_state["clf_pack_adv"] = clf_pack_adv
                        st.success("Advanced ëª¨ë¸ (RandomForest) í•™ìŠµ ì™„ë£Œ!")
                        
                    # ===== í† í”½ ë‹¨ì–´ ì€í–‰ êµ¬ì¶• (Advanced Modeìš©) =====
                    st.subheader("4. í† í”½ë³„ í•µì‹¬ ë‹¨ì–´ ì€í–‰ êµ¬ì¶• (TAB1 ì¶”ì²œ ê¸°ë°˜)")
                    with st.spinner("í† í”½ë³„ ì„±ê³¼ ìš°ìˆ˜/ì €ì¡° ë‹¨ì–´ ë¶„ì„ ì¤‘â€¦"):
                        # â˜…â˜…â˜… [ìˆ˜ì •] RandomForest ê¸°ë°˜ í•¨ìˆ˜ í˜¸ì¶œë¡œ ëŒ€ì²´ â˜…â˜…â˜…
                        topic_term_bank = build_topic_term_bank_rf_logratio(st.session_state['df_for_analysis'], topn=50) 
                    
                        st.session_state["topic_term_bank"] = topic_term_bank
                    st.success("í† í”½ ê¸°ë°˜ ìš©ì–´ ì€í–‰(RandomForest/LogRatio) êµ¬ì¶• ì™„ë£Œ! (TAB1 Advanced Modeì—ì„œ í™œìš© ê°€ëŠ¥)")

                    # ===== ê°ì„± ë¶„ì„ê¸° ìƒì„± ë¡œì§ (TAB1ìš©) =====
                    if f_lex is not None:
                        st.subheader("5. ê°ì„± ë¶„ì„ê¸° ìƒì„± (TAB1ìš©)")
                        with st.spinner("ê°ì„± ì‚¬ì „ì„ ì²˜ë¦¬í•˜ì—¬ TAB1ì—ì„œ ì‚¬ìš©í•  ë¶„ì„ê¸°ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                f_lex.seek(0)
                                lex_df = read_csv_robust(f_lex)
                                if not set(["word","score"]).issubset(lex_df.columns):
                                    st.warning("ê°ì„± ì‚¬ì „ì— 'word', 'score' ì»¬ëŸ¼ì´ ì—†ì–´ S/I ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                                    st.session_state['sentiment_pack'] = None
                                else:
                                    lex_dict = dict(zip(lex_df["word"].astype(str), lex_df["score"].astype(float)))
                                    senti_cv = TfidfVectorizer(min_df=1, stop_words=STOPWORDS_KO)
                                    texts = (df_full_for_prep["title"].fillna("") + " " + df_full_for_prep["content"].fillna("")).tolist()
                                    senti_cv.fit(texts)

                                    df_work_senti = compute_sentiment_SI(df_work, senti_cv, lex_dict)
                                    avg_s_good = df_work_senti[df_work_senti['quality_label'] == 'good']['S'].mean()
                                    avg_i_good = df_work_senti[df_work_senti['quality_label'] == 'good']['I'].mean()

                                    target_s_val = float(avg_s_good) if pd.notna(avg_s_good) else 0.0
                                    target_i_val = float(avg_i_good) if pd.notna(avg_i_good) else 0.0

                                    st.session_state['sentiment_pack'] = {
                                        'lex': lex_dict,
                                        'cv': senti_cv,
                                        'target_s': target_s_val,
                                        'target_i': target_i_val
                                    }
                                    st.session_state['lex_file_name'] = f_lex.name
                                    st.success(f"ê°ì„± ë¶„ì„ê¸°(S/I)ê°€ TAB1ì„ ìœ„í•´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ëª©í‘œ S: {target_s_val:.2f}, ëª©í‘œ I: {target_i_val:.2f})")
                            except Exception as e:
                                st.error(f"ê°ì„± ì‚¬ì „ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                                st.session_state['sentiment_pack'] = None
                    else:
                        st.session_state['sentiment_pack'] = None


                    # ë¶„ì„ ì™„ë£Œ í”Œë˜ê·¸ ë° ì‹œê°í™”ìš© ë°ì´í„° ì €ì¥
                    st.session_state['analysis_done'] = True
                    st.session_state['df_work_for_viz'] = df_work.copy()
                    st.session_state['topic_labels_for_viz'] = topic_labels
                    st.rerun()

                # --- ì‹œê°í™” ë¸”ë¡ (ë¶„ì„ ì™„ë£Œ ì‹œì—ë§Œ ì‹¤í–‰) ---
                if st.session_state.get('analysis_done', False):
                    df_work_viz = st.session_state.get('df_work_for_viz')
                    topic_labels_viz = st.session_state.get('topic_labels_for_viz', {})
                    clf_pack_adv_viz = st.session_state.get('clf_pack_adv')
                    senti_pack_viz = st.session_state.get('sentiment_pack')

                    if df_work_viz is None or topic_labels_viz is None or clf_pack_adv_viz is None:
                        st.error("ì‹œê°í™” ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        st.stop()

                    st.markdown("---")
                    st.header("ğŸ”¬ ì¶”ê°€ ë¶„ì„ ì‹œê°í™”")

                    topic_names_map = {int(k.split(' ')[1]): v.get('name', k) for k, v in topic_labels_viz.items()}
                    if 'topic_name' not in df_work_viz.columns:
                        df_work_viz['topic_name'] = df_work_viz['topic'].map(topic_names_map).fillna('ê¸°íƒ€')
                    
                    # A, B ì„¹ì…˜ì— ì ìš©ë  í† í”½ í•„í„°
                    topic_names_list = ["ì „ì²´ (All)"] + sorted(df_work_viz['topic_name'].unique().tolist())
                    filter_topic_name = st.selectbox("ğŸ”¬ ì‹œê°í™” í† í”½ í•„í„° (A, B ì„¹ì…˜ì— ì ìš©)", topic_names_list)

                    if filter_topic_name == "ì „ì²´ (All)":
                        df_viz = df_work_viz.copy() # copy() ì¶”ê°€
                    else:
                        df_viz = df_work_viz[df_work_viz['topic_name'] == filter_topic_name].copy() # copy() ì¶”ê°€

                    # =======================================
                    # A. ì£¼ì œë³„ ì„±ê³¼ ë¶„í¬ (ê¸°ì¡´ ìœ ì§€)
                    # =======================================
                    st.subheader("A. ì£¼ì œë³„ ì„±ê³¼ ë¶„í¬")
                    try:
                        fig_topic_box = px.box(
                            df_viz, x='topic_name', y='engagement', color='topic_name',
                            title=f'ì£¼ì œ(í† í”½)ë³„ ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜(Total Engagement) ë¶„í¬ ({filter_topic_name})',
                            labels={'topic_name': 'ì£¼ì œëª…', 'engagement': 'ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜(ì´í•©)'}
                        )
                        st.plotly_chart(fig_topic_box, use_container_width=True)
                    except Exception as e:
                        st.error(f"A. í† í”½ ì„±ê³¼ ì‹œê°í™” ì‹¤íŒ¨: {e}")

                    st.markdown("---")

                    # =======================================
                    # B. ê°ì„±(S/I)ê³¼ ì„±ê³¼ (ê¸°ì¡´ Cì—ì„œ ìŠ¹ê²©)
                    # =======================================
                    st.subheader(f"B. ê°ì„±(S/I)ê³¼ ì„±ê³¼ ({filter_topic_name})")
                    
                    if senti_pack_viz and senti_pack_viz.get('cv') and senti_pack_viz.get('lex'):
                        if 'S' not in df_viz.columns:
                            # compute_sentiment_SIëŠ” ì›ë³¸ dfë¥¼ ë³µì‚¬í•˜ë¯€ë¡œ, í•„í„°ë§ëœ df_vizì— ë‹¤ì‹œ ê³„ì‚°í•´ì•¼ í•¨
                            df_viz = compute_sentiment_SI(df_viz, senti_pack_viz['cv'], senti_pack_viz['lex'])

                        if 'S' in df_viz.columns and df_viz['S'].abs().sum() > 0:
                            fig_senti_scatter = px.scatter(
                                df_viz, x='S', y='engagement', color='quality_label',
                                title=f'ì½˜í…ì¸  ê°ì„±(S)ê³¼ ì„±ê³¼(Total Engagement) ê´€ê³„ ({filter_topic_name})',
                                labels={'S': 'í‰ê·  ê°ì„± ì ìˆ˜ (S)', 'engagement': 'ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜(ì´í•©)'},
                                hover_data=['title'],
                                color_discrete_map={'good': 'blue', 'medium': 'gray', 'bad': 'red'}
                            )
                            st.plotly_chart(fig_senti_scatter, use_container_width=True)
                        else:
                            st.warning(f"'{filter_topic_name}' í† í”½ì—ì„œ ìœ íš¨í•œ ê°ì„± ì ìˆ˜(S)ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. (ê°ì„± ì‚¬ì „ ë‹¨ì–´ ë¶€ì¡±)")
                    else:
                        st.caption("ğŸ’– 'ê°ì„± ì‚¬ì „ CSV'ë¥¼ ì—…ë¡œë“œí•˜ë©´ ê°ì„±-ì„±ê³¼ ê´€ê³„ ë¶„ì„ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

                    st.markdown("---")

                    # =======================================
                    # C. ìƒìœ„ Nê°œ í‚¤ì›Œë“œ ì‹œê³„ì—´ ë¶„ì„ (ì‹ ê·œ/êµì²´)
                    # =======================================
                    st.subheader("C. ìƒìœ„ Nê°œ í‚¤ì›Œë“œ ì‹œê³„ì—´ ë¶„ì„ (Good/Bad)")
                    st.caption("â”” 'Good' ë° 'Bad' ë“±ê¸‰ ì½˜í…ì¸ ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œì˜ ì‹œê°„ íë¦„ì— ë”°ë¥¸ ì‚¬ìš© ë¹ˆë„ ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

                    # ì„ íƒ ë°•ìŠ¤ ì¶”ê°€
                    selected_term_type = st.radio("ë¶„ì„í•  ë‹¨ì–´ ìœ í˜•", ["ìµœê·¼ ì¸ê¸° í‚¤ì›Œë“œ", "ì „ì²´ ê¸°ê°„ ì„±ê³¼ ìš°ìˆ˜ í‚¤ì›Œë“œ"], index=0, horizontal=True, key="c_term_type_select")
                    
                    k_top_words = st.slider("ë¶„ì„í•  í‚¤ì›Œë“œ ê°œìˆ˜ (Top-K)", 5, 20, 10, step=1, key="k_top_words_c")

                    try:
                        df_all_data = st.session_state.get('df_for_analysis')
                        if df_all_data is None or df_all_data.empty or 'date' not in df_all_data.columns:
                            st.warning("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‚ ì§œ('date') ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. TAB2ì—ì„œ CSVë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        else:
                            
                            top_keywords = []
                            if selected_term_type == "ìµœê·¼ ì¸ê¸° í‚¤ì›Œë“œ":
                                # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì¸ê¸° í‚¤ì›Œë“œ ì¶”ì¶œ (30ì¼ ì´ë‚´)
                                end_date = df_all_data['date'].max().date()
                                top_keywords = get_recent_popular_words(df_all_data, end_date, topic_id=None, k=k_top_words)
                            else: # ì „ì²´ ê¸°ê°„ ì„±ê³¼ ìš°ìˆ˜ í‚¤ì›Œë“œ
                                topic_term_bank = st.session_state.get("topic_term_bank")
                                if topic_term_bank:
                                    # ëª¨ë“  í† í”½ì—ì„œ 'good' ë‹¨ì–´ë¥¼ í•©ì³ì„œ ìƒìœ„ Kê°œ ì„ íƒ
                                    all_good_terms = {}
                                    for topic_id, data in topic_term_bank.items():
                                        if data.get("status") == "ok":
                                            # scoreê°€ Log Ratioì´ë¯€ë¡œ ì ˆëŒ“ê°’ ëŒ€ì‹  Log Ratio ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                            for term, score in data["good"]:
                                                all_good_terms[term] = all_good_terms.get(term, 0) + score
                                    top_keywords = sorted(all_good_terms.items(), key=lambda item: item[1], reverse=True)[:k_top_words]
                                    top_keywords = [term for term, score in top_keywords]
                                else:
                                    st.warning("í† í”½ ë‹¨ì–´ ì€í–‰ì´ ì—†ìŠµë‹ˆë‹¤. 'ìµœê·¼ ì¸ê¸° í‚¤ì›Œë“œ'ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")
                                    end_date = df_all_data['date'].max().date()
                                    top_keywords = get_recent_popular_words(df_all_data, end_date, topic_id=None, k=k_top_words)

                            if not top_keywords:
                                st.info("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. TAB2ì—ì„œ ë¶„ì„ì„ ì™„ë£Œí•˜ê±°ë‚˜ ë°ì´í„°ì…‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            else:
                                st.markdown(f"**ë¶„ì„ í‚¤ì›Œë“œ:** `{', '.join(top_keywords[:k_top_words])}`")

                                # ë‚ ì§œë¥¼ ì›” ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
                                df_all_data['year_month'] = df_all_data['date'].dt.to_period('M')
                                
                                # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                                plot_data = []

                                # ê° í‚¤ì›Œë“œì— ëŒ€í•´ Good/Bad ë¬¸ì„œì—ì„œ ì›”ë³„ ë¹ˆë„ ê³„ì‚°
                                for keyword in top_keywords[:k_top_words]:
                                    # ì •ê·œí‘œí˜„ì‹ ì´ìŠ¤ì¼€ì´í”„ (íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
                                    escaped_keyword = regx.escape(keyword)

                                    # 'Good' ì½˜í…ì¸ ì—ì„œì˜ ë¹ˆë„
                                    df_good_monthly = df_all_data[df_all_data['quality_label'] == 'good'].groupby('year_month')['content'].apply(lambda x: x.str.contains(escaped_keyword, case=False).sum()).reset_index(name='count')
                                    df_good_monthly['keyword'] = keyword
                                    df_good_monthly['label'] = 'Good'
                                    plot_data.append(df_good_monthly)

                                    # 'Bad' ì½˜í…ì¸ ì—ì„œì˜ ë¹ˆë„
                                    df_bad_monthly = df_all_data[df_all_data['quality_label'] == 'bad'].groupby('year_month')['content'].apply(lambda x: x.str.contains(escaped_keyword, case=False).sum()).reset_index(name='count')
                                    df_bad_monthly['keyword'] = keyword
                                    df_bad_monthly['label'] = 'Bad'
                                    plot_data.append(df_bad_monthly)

                                if plot_data and not all(df.empty for df in plot_data):
                                    df_plot = pd.concat(plot_data)
                                    df_plot['year_month'] = df_plot['year_month'].dt.to_timestamp() # Plotlyë¥¼ ìœ„í•´ datetimeìœ¼ë¡œ ë³€í™˜
                                    
                                    # í‚¤ì›Œë“œë³„ë¡œ ê·¸ë˜í”„ë¥¼ ë‚˜ëˆ„ì–´ ê·¸ë¦½ë‹ˆë‹¤.
                                    fig_keyword_trend = px.line(
                                        df_plot, x='year_month', y='count', color='label', line_dash='keyword',
                                        title=f'í‚¤ì›Œë“œë³„ ì›”ê°„ ì‚¬ìš© ë¹ˆë„ ì¶”ì´ (Good vs Bad)',
                                        labels={'year_month': 'ë‚ ì§œ', 'count': 'ì›”ê°„ ì‚¬ìš© ë¹ˆë„', 'label': 'ì½˜í…ì¸  ë“±ê¸‰', 'line_dash': 'í‚¤ì›Œë“œ'},
                                        color_discrete_map={'Good': 'blue', 'Bad': 'red'}
                                    )
                                    fig_keyword_trend.update_layout(hovermode="x unified")
                                    st.plotly_chart(fig_keyword_trend, use_container_width=True)
                                else:
                                    st.info("ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"C. í‚¤ì›Œë“œ ì‹œê³„ì—´ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")

                    st.markdown("---")

                    # =======================================
                    # D. í•µì‹¬ í”¼ì²˜ ì¶”ì„¸ (ì‹ ê·œ - ê¸°ì¡´ D ëŒ€ì²´)
                    # =======================================
                    st.subheader("D. í•µì‹¬ í”¼ì²˜ (ê¸¸ì´/ì´ë¯¸ì§€) êµ¬ê°„ë³„ ì„±ê³¼ ë¶„ì„")
                    st.caption("â”” ì‚¬ìš©ìê°€ ì§ì ‘ ì¡°ì •í•  ìˆ˜ ìˆëŠ” í”¼ì²˜(ì½˜í…ì¸  ê¸¸ì´, ì´ë¯¸ì§€ ìˆ˜)ì˜ ë³€í™”ê°€ ì„±ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë“±ê¸‰ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                    
                    feature_to_bin = st.selectbox("ë¶„ì„í•  í•µì‹¬ í”¼ì²˜ ì„ íƒ", ["content_length", "title_length", "img_count"], index=0, key="bin_feature_select")
                    
                    try:
                        df_analysis = st.session_state.get('df_for_analysis').copy() # ì›ë³¸ì—ì„œ ì „ì²´ ì‚¬ìš©

                        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° 5ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                        df_analysis[feature_to_bin] = pd.to_numeric(df_analysis[feature_to_bin], errors='coerce').fillna(0)
                        
                        if df_analysis[feature_to_bin].max() == 0:
                            st.warning(f"ì„ íƒëœ í”¼ì²˜ '{feature_to_bin}'ì˜ ê°’ì´ ëª¨ë‘ 0ì…ë‹ˆë‹¤. ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        else:
                            # 1. pd.cutì„ ì‚¬ìš©í•˜ì—¬ 5ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                            df_analysis['feature_bin'] = pd.cut(df_analysis[feature_to_bin], bins=5, include_lowest=True, duplicates='drop')
                            
                            # 2. [ì˜¤ë¥˜ ìˆ˜ì •]: Interval ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€
                            df_analysis['feature_bin'] = df_analysis['feature_bin'].astype(str) # <-- FIX: Interval to String
                            
                            # êµ¬ê°„ë³„, ë“±ê¸‰ë³„ í‰ê·  Engagement ê³„ì‚°
                            df_trend = df_analysis.groupby(['feature_bin', 'quality_label'])['engagement'].mean().reset_index()
                            
                            # í”Œë¡¯ ìƒì„±
                            fig_bin_trend = px.bar(
                                df_trend, x='feature_bin', y='engagement', color='quality_label', barmode='group',
                                title=f'{feature_to_bin} êµ¬ê°„ë³„ í‰ê·  ì½˜í…ì¸  ë§¤ë ¥ ì ìˆ˜(Engagement)',
                                labels={'feature_bin': f'{feature_to_bin} êµ¬ê°„', 'engagement': 'í‰ê·  Engagement ì ìˆ˜', 'quality_label': 'ì½˜í…ì¸  ë“±ê¸‰'},
                                color_discrete_map={'good': 'blue', 'medium': 'gray', 'bad': 'red'}
                            )
                            fig_bin_trend.update_layout(xaxis={'categoryorder': 'category ascending'})
                            st.plotly_chart(fig_bin_trend, use_container_width=True)

                    except Exception as e:
                        st.error(f"D. í•µì‹¬ í”¼ì²˜ ì¶”ì„¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")

                    st.markdown("---")

                # --- ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ ë©”ì‹œì§€ (ìœ ì§€) ---
            except Exception as e:
                st.error(f"íŒŒì¼ ë¡œë“œ ë˜ëŠ” ì´ˆê¸° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}") # â˜…â˜…â˜… try-except êµ¬ë¬¸ ì¶”ê°€ ì™„ë£Œ â˜…â˜…â˜…
                st.session_state['analysis_done'] = False 
                st.session_state['df_for_analysis'] = None
                st.stop()
        else:
            # [ìˆ˜ì • ë°˜ì˜] CSV íŒŒì¼ ì—†ì„ ë•Œ ì¹œì ˆí•œ ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ
            st.info("â¬†ï¸ **ì½˜í…ì¸  ë° ì„±ê³¼ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.** \n\níŒŒì¼ì´ ì¤€ë¹„ë˜ë©´ ë¶„ì„ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤.", icon="ğŸ“")


    # ================= TAB3 (ëª¨ë¸ ê´€ë¦¬ì) =================
    with TAB3_ADMIN:
        st.header("ğŸ”¬ ëª¨ë¸ ê´€ë¦¬ì (Admin)")
        st.info("ì´ íƒ­ì€ TAB2ì—ì„œ ë¶„ì„ì´ ì™„ë£Œëœ í›„ í™œì„±í™”ë©ë‹ˆë‹¤. í˜„ì¬ ì ìš©ëœ ëª¨ë¸ì˜ ìƒíƒœì™€ ì„±ëŠ¥ì„ ì ê²€í•©ë‹ˆë‹¤.")

        # ì„¸ì…˜ì—ì„œ ë°ì´í„° ë¡œë“œ
        df_full = st.session_state.get('df_for_analysis')
        topic_bank = st.session_state.get('topic_term_bank')
        clf_pack_adv = st.session_state.get('clf_pack_adv')
        lda_model = st.session_state.get('lda_model')
        lda_vect = st.session_state.get('lda_vect')
        topic_labels = st.session_state.get('topic_labels', {})

        if not st.session_state.get('analysis_done', False) or df_full is None or df_full.empty or 'topic' not in df_full.columns or clf_pack_adv is None or lda_model is None or topic_bank is None:
            st.error("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. TAB2ì—ì„œ ë¨¼ì € 'ë¹ ë¥¸ ë¶„ì„' ë˜ëŠ” 'ì •ë°€ ë¶„ì„'ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
        else:
            # --- 1. ë¶ˆìš©ì–´ ---
            st.subheader("1. ë¶ˆìš©ì–´(Stopwords) ê´€ë¦¬")
            with st.expander("í˜„ì¬ ì ìš© ì¤‘ì¸ ê¸°ë³¸ ë¶ˆìš©ì–´ ëª©ë¡ ë³´ê¸°"):
                st.text(f"ì´ {len(STOPWORDS_KO)}ê°œ ë‹¨ì–´:")
                st.json(STOPWORDS_KO)

            with st.expander("ë¶ˆìš©ì–´ ì˜ì‹¬ ë‹¨ì–´ ë³´ê¸° (ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´)"):
                st.markdown("í† í”½/ì„±ê³¼ì™€ ê´€ê³„ì—†ì´ **ëª¨ë“  ë¬¸ì„œì— ë„ˆë¬´ ìì£¼ ë“±ì¥**í•˜ëŠ” ë‹¨ì–´(ì˜ˆ: 10% ì´ìƒ)ì…ë‹ˆë‹¤. 'ë¯¸êµ­' ê°™ì€ ê³ ìœ ëª…ì‚¬ë³´ë‹¤ **'ê²ƒì´ë‹¤', 'ìˆë‹¤'** ê°™ì€ ì¼ë°˜ ë‹¨ì–´ê°€ ì—¬ê¸° ëœ¬ë‹¤ë©´ ë¶ˆìš©ì–´ ì¶”ê°€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
                with st.spinner("ëª¨ë“  ë¬¸ì„œì—ì„œ ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
                    suspected = get_suspected_stopwords(df_full, k=50)
                    if suspected:
                        st.warning("ì•„ë˜ ë‹¨ì–´ë“¤ì€ ì´ë¯¸ ê¸°ë³¸ ë¶ˆìš©ì–´(STOPWORDS_KO)ì— í¬í•¨ëœ ê²ƒì„ ì œì™¸í•œ ê³ ë¹ˆë„ ë‹¨ì–´ì…ë‹ˆë‹¤.")
                        st.text(", ".join(suspected))
                    else:
                        st.info("ë¶ˆìš©ì–´ ì˜ì‹¬ ë‹¨ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # --- 2. í† í”½ ë‹¨ì–´ ì€í–‰ ---
            st.subheader("2. í† í”½ë³„ í•µì‹¬ ë‹¨ì–´ ì€í–‰ (RandomForest/LogRatio ê¸°ë°˜)") # ì œëª© ìˆ˜ì •
            st.markdown("""
            [ì •ë³´] ì´ ë‹¨ì–´ ì€í–‰ì€ `build_topic_term_bank_rf_logratio` (RandomForest ì¤‘ìš”ë„ + Log Ratio) í•¨ìˆ˜ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
            - **ì„±ê³¼ ìš°ìˆ˜ ë‹¨ì–´ (Good):** ì¤‘ìš”ë„ê°€ ë†’ê³  'Good' ì½˜í…ì¸ ì— ìƒëŒ€ì ìœ¼ë¡œ ë” ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ì…ë‹ˆë‹¤. (ì¶”ì²œ)
            - **ì„±ê³¼ ì €ì¡° ë‹¨ì–´ (Bad):** ì¤‘ìš”ë„ê°€ ë†’ê³  'Bad' ì½˜í…ì¸ ì— ìƒëŒ€ì ìœ¼ë¡œ ë” ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ì…ë‹ˆë‹¤. (ë¹„ê¶Œì¥)
            """)
            st.caption("â”” ScoreëŠ” Log Ratio ê°’ì´ë©°, ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡ Good/Bad ì½˜í…ì¸  ê°„ì˜ ì‚¬ìš© ë¹ˆë„ ì°¨ì´ê°€ í¬ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.") # ì„¤ëª… ìˆ˜ì •

            if topic_labels:
                topic_names_map = {v.get('name', k): int(k.split(' ')[1]) for k,v in topic_labels.items()}
                selected_name = st.selectbox("í™•ì¸í•  í† í”½ ì„ íƒ", list(topic_names_map.keys()))

                if selected_name:
                    selected_id = topic_names_map[selected_name]

                    if selected_id not in topic_bank:
                                st.error(f"í† í”½ {selected_id}ê°€ ë‹¨ì–´ ì€í–‰ì— ì—†ìŠµë‹ˆë‹¤. (TAB2 ì¬ì‹¤í–‰ í•„ìš”)")
                    else:
                        bank_data = topic_bank[selected_id]
                        if bank_data.get("status") == "ok":
                            if bank_data.get("warning"):
                                st.warning(bank_data.get("warning"))

                            c_g, c_b, c_a = st.columns(3)
                            # Score (Log Ratio)ë„ í•¨ê»˜ í‘œì‹œ
                            c_g.dataframe({"ì„±ê³¼ ìš°ìˆ˜ ë‹¨ì–´ (Good)": [f"{w} ({s:.2f})" for w,s in bank_data['good'][:20]]})
                            c_b.dataframe({"ì„±ê³¼ ì €ì¡° ë‹¨ì–´ (Bad)": [f"{w} ({s:.2f})" for w,s in bank_data['bad'][:20]]})
                            c_a.dataframe({"ë‹¨ìˆœ ë¹ˆë„ ë‹¨ì–´ (All)": [f"{w} ({s:.0f})" for w,s in bank_data['all'][:20]]})
                        else:
                            st.error(f"'{selected_name}' í† í”½ì˜ ë‹¨ì–´ ì€í–‰ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n**ì‚¬ìœ :** {bank_data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")


            # --- 3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---
            st.subheader("3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
            st.info("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ Advanced Mode í”¼ì²˜ì…‹ê³¼ Baseline Mode í”¼ì²˜ì…‹ì— ëŒ€í•œ ì„¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ Stratified 5-Fold êµì°¨ ê²€ì¦ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.")

            # [ìˆ˜ì •] ë²„íŠ¼ í´ë¦­ ì‹œ Baseline í‰ê°€ ë¡œì§ ì¶”ê°€
            if st.button("ğŸš€ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰ (Baseline vs Advanced ë¹„êµ)") or st.session_state.get('comparison_results_baseline') is None:
                with st.spinner("Advanced Mode í”¼ì²˜ì…‹ìœ¼ë¡œ 3ê°€ì§€ ë¶„ë¥˜ê¸° ëª¨ë¸ì„ í•™ìŠµ ë° í‰ê°€ ì¤‘... (Stratified 5-Fold)"):
                    try:
                        # 1. Advanced Mode í‰ê°€ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§)
                        adv_results = evaluate_comparison_models(df_full, lda_vect)
                        st.session_state['comparison_results_adv'] = adv_results
                        
                        # 2. Baseline Mode í‰ê°€ ì‹¤í–‰ (ìƒˆë¡œìš´ ë¡œì§)
                        base_results = evaluate_baseline_models(df_full)
                        st.session_state['comparison_results_baseline'] = base_results

                    except Exception as e:
                        st.error(f"êµì°¨ ê²€ì¦ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

            adv_results = st.session_state.get('comparison_results_adv')
            base_results = st.session_state.get('comparison_results_baseline')

            if adv_results and base_results:
                # B. Baseline/Advanced í†µí•© ë¹„êµ í…Œì´ë¸”
                st.markdown("#### A. Baseline vs Advanced ëª¨ë¸ í†µí•© ì„±ëŠ¥ ë¹„êµ (5-Fold í‰ê· )")
                
                summary_data = []
                for name in ["SGDClassifier", "LogisticRegression", "RandomForestClassifier"]:
                    if name in adv_results and 'error' not in adv_results[name]:
                        # Advanced ê²°ê³¼
                        summary_data.append({
                            "ëª¨ë¸": f"Advanced ({name})",
                            "Accuracy_Mean": adv_results[name]['Accuracy_Mean'],
                            "F1_Good_Mean": adv_results[name]['F1_Good_Mean']
                        })
                    if name in base_results and 'error' not in base_results[name]:
                        # Baseline ê²°ê³¼
                        summary_data.append({
                            "ëª¨ë¸": f"Baseline ({name})",
                            "Accuracy_Mean": base_results[name]['Accuracy_Mean'],
                            "F1_Good_Mean": base_results[name]['F1_Good_Mean']
                        })

                if summary_data:
                    summary_df = pd.DataFrame(summary_data).set_index("ëª¨ë¸").sort_values("F1_Good_Mean", ascending=False).round(3)
                    st.dataframe(summary_df, use_container_width=True)
                else:
                    st.warning("ë¹„êµí•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


                # A. Advanced ëª¨ë¸ ìƒì„¸ í‰ê°€ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                st.markdown("#### B. Advanced ëª¨ë¸ ìƒì„¸ í‰ê°€ (Classification Report & CM)")
                for name, res in adv_results.items():
                    st.markdown(f"##### Advanced ({name}) ëª¨ë¸")
                    if 'error' in res:
                        st.error(res['error'])
                    else:
                        c_rep, c_cm = st.columns(2)
                        with c_rep:
                            st.text(f"Fold í‰ê·  ë©”íŠ¸ë¦­ (ì´ {res['Report_DF'].loc['N_Folds'].iloc[0]}ê°œ Fold):")
                            st.dataframe(res['Report_DF'])
                        with c_cm:
                            st.text("Total Confusion Matrix (ëª¨ë“  Fold í•©ì‚°):")
                            st.dataframe(pd.DataFrame(res['CM_Total'], index=['True: Good', 'True: Bad'], columns=['Pred: Good', 'Pred: Bad']))


    # ================= TAB4 (íŒŒì¸íŠœë‹ ê´€ë¦¬ì) =================
    with TAB4_FT:
        st.header("ğŸ¤– íŒŒì¸íŠœë‹ ê´€ë¦¬ì")
        st.info("ì´ íƒ­ì€ LLM ì œëª© ìƒì„± ëª¨ë¸(íŒŒì¸íŠœë‹ëœ GPT)ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³  ìƒˆë¡œìš´ ëª¨ë¸ IDë¥¼ ì ìš©í•˜ëŠ” ê³³ì…ë‹ˆë‹¤.")

        # --- 1. í˜„ì¬ ëª¨ë¸ ìƒíƒœ ---
        st.subheader("1. í˜„ì¬ LLM ìƒíƒœ")
        st.markdown(f"**í˜„ì¬ ì‚¬ìš© ëª¨ë¸ ID:** `{FINETUNED_MODEL_ID_CURRENT}`")
        st.markdown(f"**í˜„ì¬ í•™ìŠµ ì‘ì—… ID (Job ID):** `{st.session_state.get('ft_job_id', 'N/A')}`")
        
        if is_ft_model_ready:
            st.success("âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ê¸°ë³¸ ëª¨ë¸ ë˜ëŠ” ë”ë¯¸ IDê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. íŒŒì¸íŠœë‹ì„ í†µí•´ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.markdown("---")


        # --- 2. í•™ìŠµ ë°ì´í„° ìƒì„± ë° í•™ìŠµ ì‹œì‘ (ìë™í™”) ---
        st.subheader("2. í•™ìŠµ ë°ì´í„° ìƒì„± ë° GPT íŒŒì¸íŠœë‹ ì‹œì‘")
        st.caption("TAB2ì—ì„œ ë¶„ì„ëœ ìµœì‹  'Good' ì½˜í…ì¸  íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ë¥¼ ë§Œë“¤ê³  OpenAI í•™ìŠµ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ
        base_model_ft = st.selectbox(
            "íŒŒì¸íŠœë‹ì— ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸", 
            options=["gpt-4o-mini-2024-07-18"], # gpt-4o-minië¥¼ ì²« ë²ˆì§¸ ì˜µì…˜ìœ¼ë¡œ ì´ë™
            index=0, # [ìˆ˜ì •] gpt-4o-mini-2024-07-18 ëª¨ë¸ì„ ê¸°ë³¸(index 0)ìœ¼ë¡œ ì„ íƒ
            help="GPT-4o-miniëŠ” íŒŒì¸íŠœë‹ ê°€ëŠ¥ ì—¬ë¶€ê°€ ìì£¼ ë³€ê²½ë©ë‹ˆë‹¤. í˜„ì¬ëŠ” gpt-4o-minië¥¼ ê¸°ë³¸ìœ¼ë¡œ ê¶Œì¥í•©ë‹ˆë‹¤."
        )

        is_analysis_ready = st.session_state.get('analysis_done', False)
        
        btn_start_ft = st.button("ğŸ”¥ íŒŒì¸íŠœë‹ í•™ìŠµ ì‹œì‘ (OpenAI API í˜¸ì¶œ)", disabled=not is_analysis_ready)

        if not is_analysis_ready:
            st.info("íŒŒì¸íŠœë‹ì„ ì‹œì‘í•˜ë ¤ë©´ **TAB2ì—ì„œ 'ì •ë°€ ë¶„ì„'**ì„ ë¨¼ì € ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤.")


        if btn_start_ft:
            require_llm()
            df_full = st.session_state.get('df_for_analysis')
            topic_labels = st.session_state.get('topic_labels')

            # ì´ì¤‘ ì²´í¬ (ë²„íŠ¼ ë¹„í™œì„±í™”ë¡œ ëŒ€ë¶€ë¶„ ì²˜ë¦¬ë˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´)
            if df_full is None or df_full.empty or topic_labels is None:
                st.error("âš ï¸ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•˜ë ¤ë©´ TAB2ì—ì„œ 'ì •ë°€ ë¶„ì„'ì„ ë¨¼ì € ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("LLM í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ë° OpenAI í•™ìŠµ ì‘ì—… ì‹œì‘ ì¤‘..."):
                    try:
                        # run_finetuning_job í•¨ìˆ˜ í˜¸ì¶œ (analytics_core.pyì— ì¶”ê°€ë˜ì–´ì•¼ í•¨)
                        # st.info/st.success ë©”ì‹œì§€ëŠ” run_finetuning_job ë‚´ë¶€ì— ìˆìŠµë‹ˆë‹¤.
                        new_job_id = run_finetuning_job(df_full, topic_labels, base_model=base_model_ft)
                        st.session_state['ft_job_id'] = new_job_id
                        st.success(f"ğŸ‰ íŒŒì¸íŠœë‹ ì‘ì—… ì‹œì‘ ì™„ë£Œ! Job ID: `{new_job_id}`")
                        st.balloons()
                        st.info("íŒŒì¸íŠœë‹ì€ ìˆ˜ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. OpenAI ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                        st.rerun()
                    except APIError as e:
                        st.error(f"âŒ OpenAI API ì˜¤ë¥˜ (ì¸ì¦, í• ë‹¹ëŸ‰ ë˜ëŠ” ë°ì´í„° ë¬¸ì œ): {e}")
                    except Exception as e:
                        st.error(f"âŒ íŒŒì¸íŠœë‹ ì‹œì‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown("---")
        
        # --- 3. ëª¨ë¸ ID ì ìš© (íŒŒì¸íŠœë‹ ê²°ê³¼ ë°˜ì˜) ---
        st.subheader("3. í•™ìŠµ ì‘ì—… ìƒíƒœ í™•ì¸ ë° ëª¨ë¸ ID ì ìš©")
        st.caption("íŒŒì¸íŠœë‹ ì‘ì—…ì´ ì™„ë£Œë˜ë©´, OpenAIì—ì„œ ë°œê¸‰ë°›ì€ **ìƒˆë¡œìš´ ëª¨ë¸ ID**ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ê±°ë‚˜, ìƒíƒœ í™•ì¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
        
        # í•™ìŠµ ì‘ì—… ìƒíƒœ í‘œì‹œ ë° ì—…ë°ì´íŠ¸ ë²„íŠ¼
        job_id_current = st.session_state.get('ft_job_id')
        
        if job_id_current and LLM_OK:
            if st.button(f"ğŸ”„ í•™ìŠµ Job ID `{job_id_current[:15]}...` ìƒíƒœ í™•ì¸ ë° ID ê°€ì ¸ì˜¤ê¸°"):
                require_llm()
                with st.spinner(f"Job ID `{job_id_current}`ì˜ ìƒíƒœë¥¼ ì¡°íšŒ ì¤‘..."):
                    try:
                        # OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ëŠ” analytics_coreì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
                        # client ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¡°íšŒ
                        job_info = client.fine_tuning.jobs.retrieve(job_id_current)
                        status = job_info.status
                        
                        st.markdown(f"**í˜„ì¬ ìƒíƒœ:** `{status}`")
                        
                        if status == 'succeeded' and job_info.fine_tuned_model:
                            new_ft_model_id = job_info.fine_tuned_model
                            st.session_state['ft_model_id'] = new_ft_model_id
                            st.success(f"âœ… í•™ìŠµ ì„±ê³µ! ìƒˆë¡œìš´ ëª¨ë¸ ID `{new_ft_model_id}`ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.balloons()
                            st.rerun()
                        elif status in ['running', 'queued']:
                            st.warning("â³ í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        elif status == 'failed':
                            st.error("âŒ í•™ìŠµì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. OpenAI ëŒ€ì‹œë³´ë“œì—ì„œ ì›ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")
                        
                    except APIError as e:
                        st.error(f"Job ID ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    except Exception as e:
                        st.error(f"Job ID ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

        # ìˆ˜ë™ ëª¨ë¸ ID ì…ë ¥ í•„ë“œ
        new_ft_model_id_input = st.text_input(
            "ìˆ˜ë™ìœ¼ë¡œ íŒŒì¸íŠœë‹ ëª¨ë¸ ID ì…ë ¥ (ft:gpt-3.5-turbo...)", 
            value=FINETUNED_MODEL_ID_CURRENT,
            key="ui_new_ft_model_id"
        )

        if st.button("âœ… ìƒˆ ëª¨ë¸ ID ìˆ˜ë™ ì ìš©"):
            if new_ft_model_id_input.startswith("ft:"):
                st.session_state['ft_model_id'] = new_ft_model_id_input
                st.success(f"ìƒˆ ëª¨ë¸ ID `{new_ft_model_id_input[:30]}...`ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. TAB1ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                st.rerun()
            else:
                st.error("ìœ íš¨í•œ íŒŒì¸íŠœë‹ ëª¨ë¸ ID í˜•ì‹(ft:...)ì„ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == '__main__':
    main()